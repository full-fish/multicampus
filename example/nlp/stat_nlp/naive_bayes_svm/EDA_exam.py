"""
# ì—¬ì„±ì˜ë¥˜ ë¦¬ë·° ë°ì´í„° EDA ì‹¤ìŠµ ë…¸íŠ¸ë¶

ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì—¬ì„±ì˜ë¥˜ ë¼ë²¨ë§ ë°ì´í„°(JSON)ë¥¼ ì´ìš©í•´ ë‹¤ìŒê³¼ ê°™ì€ íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

1. ë°ì´í„° ê¸°ë³¸ êµ¬ì¡° ë° ê²°ì¸¡ì¹˜ í™•ì¸
2. ë¦¬ë·° ê¸¸ì´(ë¬¸ì ìˆ˜, ë‹¨ì–´ ìˆ˜) ë¶„í¬ ë¶„ì„
3. ë¦¬ë·° ë‚ ì§œ ë¶„í¬ ë¶„ì„
4. ReviewScore ë¶„í¬ ë° ê¸¸ì´ì™€ì˜ ê´€ê³„
5. GeneralPolarity(ì „ì²´ ê°ì„±) ë¶„í¬ ë¶„ì„
6. Aspect ê¸°ë°˜ EDA (Aspect ë¹ˆë„, Aspectë³„ ê°ì„± ë¶„í¬, ì‚¬ì´ì¦ˆ/ê°€ê²© vs ReviewScore)
7. WordCloud / N-gram / TF-IDF ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„
8. Aspectë³„ ëŒ€í‘œ ë¬¸ì¥ ì‚´í´ë³´ê¸°

> **ì£¼ì˜:** ì•„ë˜ ê²½ë¡œ(`JSON_PATH`)ë¥¼ ë³¸ì¸ì˜ íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •í•œ ë’¤ ì‹¤í–‰í•˜ì„¸ìš”."""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import re
from konlpy.tag import Okt
from wordcloud import WordCloud

okt = Okt()
# N-gram, TF-IDFìš© ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

WORDCLOUD_FONT_PATH = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
# í•œê¸€
from matplotlib import font_manager, rc
import platform

if platform.system() == "Windows":
    plt.rc("font", family="Malgun Gothic")
elif platform.system() == "Darwin":  # macOS
    plt.rc("font", family="AppleGothic")
else:  # ë¦¬ëˆ…ìŠ¤ ê³„ì—´ (ì˜ˆ: êµ¬ê¸€ì½”ë©, ìš°ë¶„íˆ¬)
    plt.rc("font", family="NanumGothic")

plt.rcParams["axes.unicode_minus"] = False  # ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€

# ----------------------------------------

# JSON íŒŒì¼ ê²½ë¡œë¥¼ ë³¸ì¸ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”.
base_dir = Path(r"stat_nlp/naive_bayes_svm/Sample/02.ë¼ë²¨ë§ë°ì´í„°")  # ì˜ˆì‹œ

# ë¶ˆìš©ì–´
with open(
    "stat_nlp/stopwords-ko.txt",
    encoding="utf-8",
) as f:
    stopwords = set(w.strip() for w in f if w.strip())

"""
##! 1. ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì •ë³´ í™•ì¸
""" ""

df = []
i = 1
TARGET = 600
counts = {1: 0, 0: 0, -1: 0}
while True:
    path = f"{base_dir}/ì‡¼í•‘ëª°/01. íŒ¨ì…˜/1-1. ì—¬ì„±ì˜ë¥˜/1-1.ì—¬ì„±ì˜ë¥˜({i}).json"
    try:
        print(i, "ë²ˆ íŒŒì¼ ì½ìŒ")
        temp = pd.read_json(path)

        if all(value >= TARGET for value in counts.values()):
            print("ëª¨ë“  í´ë˜ìŠ¤ 600ê°œì”© ìˆ˜ì§‘ ì™„ë£Œ")
            break

        for _, row in temp.iterrows():
            if pd.isna(row["GeneralPolarity"]):
                continue
            if counts[int(row["GeneralPolarity"])] < TARGET:
                counts[int(row["GeneralPolarity"])] += 1
                df.append(row.to_dict())

        i += 1
    except Exception as e:
        print(i, "ë²ˆ íŒŒì¼ì—ì„œ ì—ëŸ¬ ë°œìƒ")
        print("ì—ëŸ¬ ë‚´ìš©:", e)
        break
df = pd.DataFrame(df)
df = df.dropna(subset=["RawText", "GeneralPolarity", "ReviewScore", "RDate"])
print("\ndf.head()", df.head())

"""
##! 2. ë¦¬ë·° ê¸¸ì´ ë¶„ì„ (ë¬¸ì ìˆ˜, ë‹¨ì–´ ìˆ˜)

- RawText ê¸¸ì´(ë¬¸ì ìˆ˜)
- RawText ë‹¨ì–´ ìˆ˜
- ê¸¸ì´ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨ / ë°•ìŠ¤í”Œë¡¯
""" ""

df["char_len"] = df["RawText"].str.len()
df["word_len"] = df["RawText"].str.split().str.len()
plt.figure(figsize=(15, 6))

plt.subplot(1, 2, 1)
df["char_len"].hist(bins=50, color="skyblue", edgecolor="black")
plt.title("RawTextì˜ ê¸€ì ê°œìˆ˜", fontsize=15)
plt.xlabel("ê¸€ì ê°œìˆ˜")
plt.ylabel("ë¦¬ë·° ìˆ˜")
plt.grid()

plt.subplot(1, 2, 2)
plt.boxplot(df["char_len"].dropna())
plt.title("RawTextì˜ ê¸€ì ê°œìˆ˜", fontsize=15)
plt.xlabel("ê¸€ì ê°œìˆ˜")
plt.tight_layout()
# plt.show()


plt.figure(figsize=(15, 6))

plt.subplot(1, 2, 1)
df["word_len"].hist(bins=50, color="lightcoral", edgecolor="black")
plt.title("RawTextì˜ ë‹¨ì–´ ê°œìˆ˜", fontsize=15)
plt.xlabel("ë‹¨ì–´ ê°œìˆ˜")
plt.ylabel("ë¦¬ë·° ìˆ˜")
plt.grid()

plt.subplot(1, 2, 2)
plt.boxplot(df["word_len"].dropna())
plt.title("RawTextì˜ ë‹¨ì–´ ê°œìˆ˜", fontsize=15)
plt.xlabel("ë‹¨ì–´ ê°œìˆ˜")
plt.tight_layout()
# plt.show()

"""
##! 3. ë¦¬ë·° ë‚ ì§œ(RDate) ë¶„í¬

- ë‚ ì§œ ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜
- ì „ì²´ ê¸°ê°„ ë™ì•ˆ ë¦¬ë·°ê°€ ì–´ë–»ê²Œ ë¶„í¬í•˜ëŠ”ì§€ í™•ì¸
""" ""
df["RDate_datetime"] = pd.to_datetime(df["RDate"], format="%Y%m%d", errors="coerce")

df = df.dropna(subset=["RDate_datetime"])
# print(df.head().to_markdown())
review_counts_daily = df.groupby(df["RDate_datetime"].dt.date).size()

plt.figure(figsize=(15, 6))

review_counts_daily.plot(kind="line", color="darkblue", linewidth=1)
plt.title("ì „ì²´ ê¸°ê°„ ë™ì•ˆ ë¦¬ë·° ìˆ˜ ë¶„í¬", fontsize=15)
plt.xlabel("ë‚ ì§œ")
plt.ylabel("ë¦¬ë·° ê°œìˆ˜")
plt.xticks(rotation=45)
plt.grid()
plt.tight_layout()
# plt.show()

"""
##! 4. ReviewScore ë¶„í¬ ë° ê¸¸ì´ì™€ì˜ ê´€ê³„
""" ""
# ë¦¬ë·° ê°œìˆ˜ ë¶„í¬
df["ReviewScore"] = df["ReviewScore"].astype(int)
review_score_counts = df["ReviewScore"].value_counts().sort_index()

plt.figure(figsize=(8, 5))

review_score_counts.plot(kind="bar", color="skyblue", edgecolor="black")

plt.title("ë¦¬ë·° ì ìˆ˜ ë¶„í¬", fontsize=15)
plt.xlabel("ì ìˆ˜")
plt.xticks(rotation=0)
plt.ylabel("ë¦¬ë·° ê°œìˆ˜1")
plt.grid()
plt.tight_layout()
# plt.show()

# ê¸€ì ìˆ˜ì™€ ë¦¬ë·° ì ìˆ˜ ê´€ê³„
plt.figure(figsize=(15, 6))
plt.subplot(1, 2, 1)
sns.boxplot(
    x="ReviewScore", y="char_len", data=df, hue="ReviewScore", palette="viridis"
)
plt.title("ReviewScoreë³„ ë¦¬ë·° ê¸¸ì´(ë¬¸ì ìˆ˜) ë¶„í¬", fontsize=15)
plt.xlabel("ë¦¬ë·° ì ìˆ˜ (ReviewScore)")
plt.ylabel("ë¦¬ë·° ê¸¸ì´ (ë¬¸ì ìˆ˜)")
plt.grid()
plt.tight_layout()

plt.subplot(1, 2, 2)
sns.boxplot(
    x="ReviewScore", y="word_len", data=df, hue="ReviewScore", palette="viridis"
)
plt.title("ReviewScoreë³„ ë¦¬ë·° ê¸¸ì´(ë‹¨ì–´ ìˆ˜) ë¶„í¬", fontsize=15)
plt.xlabel("ë¦¬ë·° ì ìˆ˜ (ReviewScore)")
plt.ylabel("ë¦¬ë·° ê¸¸ì´ (ë‹¨ì–´ ìˆ˜)")
plt.grid()
plt.tight_layout()

"""
##! 5. GeneralPolarity(ì „ì²´ ê°ì„±) ë¶„í¬
- -1: ë¶€ì •, 0: ì¤‘ë¦½, 1: ê¸ì •
""" ""
df["GeneralPolarity"] = df["GeneralPolarity"].astype(int)
generalPolarity_sorted = df["GeneralPolarity"].value_counts().sort_index()
generalPolarity_total_count = df["GeneralPolarity"].value_counts().sum()


def pie_format(percent, allvals):
    """
    í¼ì„¼íŠ¸(pct)ë¥¼ ì…ë ¥ë°›ì•„ 'ê°œìˆ˜ (ë¹„ìœ¨%)' í˜•ì‹ì˜ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    absolute = int(np.round(percent / 100.0 * allvals))

    return f"{absolute} ({percent:.1f}%)"


plt.figure(figsize=(7, 7))
plt.pie(
    generalPolarity_sorted,
    labels=["ë¶€ì •", "ì¤‘ë¦½", "ê¸ì •"],
    autopct=lambda percent: pie_format(percent, generalPolarity_total_count),
    startangle=90,
    colors=["lightcoral", "lightgray", "lightgreen"],
    wedgeprops={"edgecolor": "black"},
)
plt.tight_layout()
# plt.show()

"""
##! 6. Aspect ê¸°ë°˜ EDA

- Aspects ì»¬ëŸ¼ì„ í–‰ ë‹¨ìœ„ë¡œ í’€ì–´ì„œ í•˜ë‚˜ì˜ DataFrame(`aspect_df`) ìƒì„±
- Aspect ì¢…ë¥˜ë³„ ë¹ˆë„
- Aspectë³„ ê°ì„± ë¶„í¬(-1/0/1)
- "ì‚¬ì´ì¦ˆ" / "ê°€ê²©"ì— ëŒ€í•œ ê°ì„±ê³¼ ReviewScore ê´€ê³„ ë³´ê¸°"""
# aspect_df = [row for row in df["Aspects"]]
# print("\naspect_df", (aspect_df))
temp = df[["RawText", "GeneralPolarity", "ReviewScore", "RDate", "Aspects"]].copy()

# í•œ ë¦¬ë·° ì•ˆì˜ ì—¬ëŸ¬ Aspectë¥¼ í–‰ìœ¼ë¡œ ë¶„ë¦¬
# explode í•˜ë©´ ë¦¬ìŠ¤íŠ¸ ê°œìˆ˜ë§Œí¼ í–‰ì´ ìƒê¹€
temp = temp.explode("Aspects").dropna(subset=["Aspects"])
# json_normaliz: objë¥¼ ì»¬ëŸ¼í™”í•´ì„œ í¼ì¹¨
aspect_info = pd.json_normalize(temp["Aspects"])
# print("\n", temp.iloc[0])
# print("\n", aspect_info.iloc[0])
# print("\ntmr", len(temp), len(aspect_info))
aspect_df = pd.concat(
    [
        temp.drop(columns=["Aspects"]).reset_index(drop=True),
        aspect_info.reset_index(drop=True),
    ],
    axis=1,
)
# print("\naspect_df.head()", aspect_df.head())
aspect_counts = aspect_df["Aspect"].value_counts()
SentimentPolarity_counts = aspect_df["SentimentPolarity"].value_counts().sort_index()
top_N = 20
plt.figure(figsize=(15, 6))
plt.subplot(1, 2, 1)
aspect_counts.head(top_N).sort_values().plot(kind="barh")

plt.title(f"Aspectë³„ ì–¸ê¸‰ ê°œìˆ˜ (ìƒìœ„ {top_N}ê°œ)", fontsize=15)
plt.xlabel("ì–¸ê¸‰ ê°œìˆ˜")
plt.ylabel("Aspect")
plt.grid(axis="x")
plt.tight_layout()

# pie ê·¸ë˜í”„
plt.subplot(1, 2, 2)

SentimentPolarity_sorted = aspect_df["SentimentPolarity"].value_counts().sort_index()
SentimentPolarity_total_count = aspect_df["SentimentPolarity"].value_counts().sum()
plt.pie(
    SentimentPolarity_sorted,
    labels=["ë¶€ì •", "ì¤‘ë¦½", "ê¸ì •"],
    autopct=lambda percent: pie_format(percent, SentimentPolarity_total_count),
    startangle=90,
    colors=["lightcoral", "lightgray", "lightgreen"],
    wedgeprops={"edgecolor": "black"},
)
plt.tight_layout()
# plt.show()

# ì‚¬ì´ì¦ˆ" / "ê°€ê²©"ì— ëŒ€í•œ ê°ì„±ê³¼ ReviewScore ê´€ê³„ ë³´ê¸°
target_aspects_df = aspect_df[aspect_df["Aspect"].isin(["ì‚¬ì´ì¦ˆ", "ê°€ê²©"])].copy()

score_analysis = target_aspects_df.groupby(["Aspect", "SentimentPolarity"])[
    "ReviewScore"
].mean()
print("\nscore_analysis\n", score_analysis)

score_pivot = score_analysis.unstack()  # 2ì°¨ì› í˜•íƒœë¡œ í¼ì¹¨

# 4. ì‹œê°í™”
plt.figure(figsize=(10, 6))

score_pivot.plot(
    kind="bar",
    rot=0,
    ax=plt.gca(),
    color=[
        "lightcoral",
        "lightgray",
        "lightgreen",
    ],  # ë¶€ì •(-1), ì¤‘ë¦½(0), ê¸ì •(1)ì— ë§ì¶¤
    edgecolor="black",
)

plt.title("'ì‚¬ì´ì¦ˆ'/'ê°€ê²©' Aspect ê°ì„±ë³„ í‰ê·  ReviewScore", fontsize=15)
plt.xlabel("Aspect ê°ì„± ë¶„ë¥˜ (-1:ë¶€ì •, 0:ì¤‘ë¦½, 1:ê¸ì •)", fontsize=12)
plt.ylabel("í‰ê·  ReviewScore", fontsize=12)
plt.legend(title="Aspect")
plt.grid(axis="y")
plt.tight_layout()
plt.show()
"""
##! 7. í…ìŠ¤íŠ¸ ê¸°ë°˜ ë¶„ì„: N-gram(CountVectorizer) / TF-IDF(ê¸/ë¶€ì • ìƒìœ„ 20ê°œ ë‹¨ì–´ ì¶”ì¶œ)
""" ""


def preprocess(text):
    str_reg = re.sub(r"[^ê°€-í0-9a-zA-Z\s]", "", text).lower()
    pos = okt.pos(str_reg, norm=True, stem=True, join=True)
    pos = [word.split("/") for word in pos]
    filtered_pos = [
        word
        for word, tag in pos
        if word and word not in stopwords and tag in ["Noun", "Verb", "Adjective"]
    ]
    return filtered_pos


def get_top_ngrams(df_series, top_n=20):
    vectorizer = CountVectorizer(
        tokenizer=preprocess, token_pattern=None, ngram_range=(1, 2)
    )
    X = vectorizer.fit_transform(df_series)
    feature_names = vectorizer.get_feature_names_out()

    word_scores = X.sum(axis=0).A1

    scores_series = pd.Series(word_scores, index=feature_names)
    return scores_series.nlargest(top_n)


def get_top_tfidf(df, polarity, top_n=10):
    df_filtered = df[df["GeneralPolarity"] == polarity]["RawText"]

    vectorizer = TfidfVectorizer(
        tokenizer=preprocess, token_pattern=None, ngram_range=(1, 1)
    )
    X = vectorizer.fit_transform(df_filtered)
    feature_names = vectorizer.get_feature_names_out()

    word_scores = X.sum(axis=0).A1

    scores_series = pd.Series(word_scores, index=feature_names)
    return scores_series.nlargest(top_n)


print("--- N-gram ë¹ˆë„ ë¶„ì„ ---")
top_ngrams = get_top_ngrams(df["RawText"], 10)
print(top_ngrams.to_markdown(floatfmt=".0f"))

print("\n--- TF-IDF ë¶„ì„ - ê¸ì • ë¦¬ë·° ---")
top_tfidf_pos = get_top_tfidf(df, 1, 10)
print(top_tfidf_pos.to_markdown(floatfmt=".3f"))

print("\n--- [TF-IDF ë¶„ì„ - ë¶€ì • ë¦¬ë·° ---")
top_tfidf_neg = get_top_tfidf(df, -1, 10)
print(top_tfidf_neg.to_markdown(floatfmt=".3f"))

"""
##! 8. Aspectë³„ ëŒ€í‘œ ë¬¸ì¥ ì‚´í´ë³´ê¸°(ë¬¸ì¥ ê¸¸ì´ ê¸°ì¤€)
- ì‚¬ì´ì¦ˆ ë¶€ì • ë¬¸ì¥ Top 20
- ê°€ê²© ê¸ì • ë¬¸ì¥ Top 20
""" ""
aspect_df["char_len"] = aspect_df["RawText"].str.len()
print("\n\n\n", aspect_df.head())

size_neg_top20 = (
    aspect_df[
        (aspect_df["Aspect"] == "ì‚¬ì´ì¦ˆ") & (aspect_df["SentimentPolarity"] == "-1")
    ]
    .sort_values("char_len", ascending=False)
    .head(20)[["RawText"]]
)
cost_pos_top20 = (
    aspect_df[(aspect_df["Aspect"] == "ê°€ê²©") & (aspect_df["SentimentPolarity"] == "1")]
    .sort_values("char_len", ascending=False)
    .head(20)[["RawText"]]
)

print(size_neg_top20)
print(cost_pos_top20)

##! wordcloud
# dfì˜ RawText ì»¬ëŸ¼ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ê¸´ ë¬¸ìì—´(corpus)ë¡œ ê²°í•©í•©ë‹ˆë‹¤.
text_corpus = " ".join(df["RawText"].astype(str))

# WordCloud ê°ì²´ ìƒì„±
wordcloud = WordCloud(
    font_path=WORDCLOUD_FONT_PATH,  # ğŸŒŸ ìˆ˜ì •ëœ ë§¥ìš© í°íŠ¸ ê²½ë¡œ ì‚¬ìš© ğŸŒŸ
    stopwords=stopwords,
    background_color="white",
    width=800,
    height=600,
    max_words=100,
    scale=2,
)

# 4. WordCloud ìƒì„±
wordcloud.generate(text_corpus)

# 5. ì‹œê°í™”
plt.figure(figsize=(10, 8))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.title("ì „ì²´ ë¦¬ë·° í…ìŠ¤íŠ¸ WordCloud", fontsize=15)
plt.tight_layout()
plt.show()
